{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc1a552d-f004-476b-88cb-dabd3d84e841",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **1. Import The Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f041e84-1d1d-48ce-a6de-3ababf74879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries and dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "import xgboost\n",
    "import warnings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, classification_report, roc_auc_score, roc_curve, auc, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from math import sqrt\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from joblib import dump, load\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da697491-1159-4f78-bd24-a64c95b48a5b",
   "metadata": {},
   "source": [
    "# **2. Load The Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d40e8a-d53e-4cda-96dd-83e2b9ae42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Spotify.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf697c-67be-48bf-826e-f3daa7fcc34c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# **3. Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca652388-66ea-41c5-86ae-1bb94230e5b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **3.1 Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5c601-cb22-427d-bf56-ee10c68dc697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3eef8-7ec7-4d0e-92e6-f576a72909b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c0907-0983-45cd-9c71-b79cf8c4a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edc100e-6056-4857-a926-99a7b60abee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af4c49-aa12-412d-b1d3-47d840685316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceeca26d-4689-4840-a84d-bd5966c22491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_with_nas = ['danceability', 'energy', 'key', 'mode', 'loudness', 'speechiness',\n",
    "                    'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
    "                    'duration']\n",
    "\n",
    "rows_with_nas = df.loc[df[columns_with_nas].isna().any(axis=1)]\n",
    "\n",
    "rows_with_nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d117f3-7962-4887-9bee-7874e59f8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify = df.drop(columns = ['Unnamed: 0', 'uri', 'artist_names', 'artist_img', 'artist_individual', \n",
    "                             'album_cover', 'artist_id', 'track_name', 'source', 'pivot', 'release_date', 'collab'])\n",
    "spotify.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3c93a-463d-41aa-91b6-8e983d76d2f5",
   "metadata": {},
   "source": [
    "## **3.2 Understand Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd335aae-bdde-487c-92ac-c081ddd5b1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify['week'] = pd.to_datetime(spotify['week'], errors = 'coerce')\n",
    "spotify['week_of_year'] = spotify['week'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6247231-065e-4022-a676-5c3b03f303e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    'rank', 'artists_num', 'album_num_tracks', 'peak_rank',\n",
    "    'previous_rank', 'weeks_on_chart', 'streams', 'danceability',\n",
    "    'energy', 'key', 'mode', 'loudness', 'speechiness',\n",
    "    'acousticness', 'instrumentalness', 'liveness', 'valence',\n",
    "    'tempo', 'duration', 'week_of_year'\n",
    "]\n",
    "\n",
    "# Convert each specified column to numeric, coercing errors to NaN\n",
    "for column in numeric_columns:\n",
    "    spotify[column] = pd.to_numeric(spotify[column], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f2a0d9-a2c4-40f7-9783-2a44db56ec3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spotify.describe(percentiles = [0.1, 0.25, 0.5, 0.75, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6edd3-9a86-49d4-b7df-856c2132d123",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = spotify[numeric_columns].corr()\n",
    "\n",
    "sns.heatmap(corr, cmap = \"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40daee4c-16f1-407f-a577-c6d779732802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a95d7b9-b6c9-4d6d-a3be-31ad49a85dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spotify['streams'].hvplot.hist(bins = 10000000, title = 'Streams Distribution').opts(xformatter = '%.0f', yformatter = '%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dac25a-3986-420c-81ae-35f21c1b05d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **3.3 Understand Categorical Features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562463b8-8165-43d9-96be-57a265d9128c",
   "metadata": {},
   "source": [
    "### **3.3.1 Country**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c53b1-1514-4949-8248-4911bab27973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.stripplot(y = 'country', x = 'streams', data = spotify, hue = 'country', jitter = True, legend = False)\n",
    "plt.show()\n",
    "spotify['country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1413eea-5a6f-45b5-a4e8-69cce2f049c2",
   "metadata": {},
   "source": [
    "### **3.3.2 Language**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f472d4-6a49-4492-8c32-3566a28c0b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "sns.stripplot(y = 'language', x = 'streams', data = spotify, hue = 'language', jitter = True, legend = False)\n",
    "plt.show()\n",
    "spotify['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb477461-666f-48db-bd87-ff8bc38b6a9f",
   "metadata": {},
   "source": [
    "### **3.3.3 Region**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8660563f-dba8-4e71-af7b-48d43f7f0c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.stripplot(y = 'region', x = 'streams', data = spotify, hue = 'region', jitter = True, legend = False)\n",
    "plt.show()\n",
    "spotify['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a24e4-099d-4834-88b7-48bc08ee240b",
   "metadata": {},
   "source": [
    "### **3.3.4 Artist_genre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f662fc43-2901-4ce9-af1d-8a9be56313fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50, 10))\n",
    "sns.stripplot(y = 'artist_genre', x = 'streams', data = spotify, hue = 'artist_genre', jitter = True, legend = False)\n",
    "plt.show()\n",
    "spotify['artist_genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd07463-68e3-4fa4-9bbc-1829e2ab7b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_filter = spotify.loc[(spotify['artist_genre'] != '0') & (spotify['country'] != 'Global') & (spotify['language'] != 'Global')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fa23c-638d-44e4-96d3-7a654de7df41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "country_top10 = spotify_filter.groupby('country')['streams'].sum().sort_values(ascending = False)\n",
    "top10_country = country_top10.index[:10]\n",
    "top10_country = top10_country.tolist()\n",
    "top10_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836c9a2-57f7-43d9-865e-4338899e8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_of_streams = spotify_filter.groupby('artist_genre')['streams']\n",
    "sum_of_streams = group_of_streams.sum()\n",
    "genre_top10 = sum_of_streams.sort_values(ascending = False)\n",
    "top10_genre = genre_top10.index[:10]\n",
    "top10_genre = top10_genre.tolist()\n",
    "top10_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fc4849-be87-4f11-9021-ef80205613a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_filter = spotify_filter.loc[(spotify_filter['country'].isin(top10_country)) & \n",
    "                                    (spotify_filter['artist_genre'].isin(top10_genre))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4040e2d9-0e91-47b3-968c-e8bf390349b4",
   "metadata": {},
   "source": [
    "After very basic Exploratory Data Analysis, we have to do some data cleaning and data preprocessing. We need three steps to finish this:\n",
    "\n",
    "1.   Encode the categorical feature.\n",
    "2.   Impute the missing value for both numeric and categorical feature.\n",
    "3.   Scale out feature, which can be better for our models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92f23b6-a1e2-4acc-86b3-df1e1bac1163",
   "metadata": {},
   "source": [
    "# **4. Feature Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ba9dae-c4a1-4059-965f-d069aba1de15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **4.1 Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646e7a8-f3a3-4634-a05a-abcc286d0d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_country = pd.get_dummies(spotify_filter['country']).astype(np.int64)\n",
    "d_language = pd.get_dummies(spotify_filter['language']).astype(np.int64)\n",
    "d_region = pd.get_dummies(spotify_filter['region']).astype(np.int64)\n",
    "#d_artist_genre = pd.get_dummies(spotify_filter['artist_genre']).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97502e5-7094-4e48-b466-c25291dce29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the genres into numbers 0-9\n",
    "\n",
    "codes, unique = pd.factorize(spotify_filter['artist_genre'])\n",
    "spotify_filter['genre'] = codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0aea9-e7d0-4da6-939e-49d5c9338158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map encoded labels to artist genres\n",
    "genre_mapping = {code: genre for code, genre in enumerate(unique)}\n",
    "\n",
    "# Display the mapping\n",
    "genre_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91c77f4-c35f-4b00-a08a-43e70187d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe, drop the previous categorical features, add new dummy variables, check for null\n",
    "temp_spotify = spotify_filter.drop(['country', 'language', 'region', 'artist_genre', 'week'], axis = 1)\n",
    "spotify_df = pd.concat([temp_spotify, d_country, d_language, d_region], axis = 1)\n",
    "spotify_df.reset_index(inplace = True)\n",
    "spotify_df.drop(columns = ['index'], inplace = True)\n",
    "spotify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f1c2a-fec3-4e2b-889d-8cf186d1dcac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spotify_df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b9e02c-6ac8-4c5a-a1e3-453530efad6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spotify_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd8cec-edec-49ce-af36-ed617c35466d",
   "metadata": {},
   "source": [
    "## **4.2 Split The Features And Target Sets Into Training And Testing Datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ac406-6dcc-4149-8378-7faf5c289bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = spotify_df.drop(columns = ['genre'])\n",
    "y = spotify_df['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2ab4a-7e81-4669-b69a-aa6bdd49239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739dd891-e9a4-458a-a716-6ede93adae86",
   "metadata": {},
   "source": [
    "## **4.3 Features Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1185c3-fcac-4224-84b1-452f4c5cf4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40296ac5-4611-4868-9e42-59736499fc97",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **4.3.1 Undersampling the Minority Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0113e3f-4e86-48de-957e-4b2f4da06d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc02d27-f950-41da-a397-588b5bd4e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ClusterCentroids\n",
    "cc = ClusterCentroids(random_state = 1)\n",
    "\n",
    "# Fit the cluster centroids model to the traning data\n",
    "X_under_resampled, y_under_resampled = cc.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e18d08-0956-4dc5-9f06-2893d8970be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_under_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc8c761-3860-4118-b730-37e5f8b66450",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **4.3.2 Oversampling the Minority Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb409118-e273-4969-b6ef-5d3198f562ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomOverSampler(random_state = 42)\n",
    "\n",
    "# Fit the data to the model\n",
    "X_over_resampled, y_over_resampled = rus.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f49b47-3560-49b9-b1b3-763b2e6163e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_over_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17365082-8644-4c30-ad9f-ad91d565975f",
   "metadata": {},
   "source": [
    "# **5. Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6202b01e-90e1-4ceb-a47c-cfa31e26c48d",
   "metadata": {},
   "source": [
    "## **5.1 Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb1373-0f58-496d-93d0-727a58eef7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':[55, 60, 65], 'max_depth':[15, 18, 20]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25dcd08-9898-48c2-a1ec-2b5bf1cbd4ec",
   "metadata": {},
   "source": [
    "### **5.1.1 Undersample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8555cb-1c3d-4e00-961a-71134a0854df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_under = RandomForestClassifier(random_state = 2, max_features = 'sqrt')\n",
    "clf_under = GridSearchCV(estimator = rf_under, param_grid = param_grid, cv = 5)\n",
    "clf_under.fit(X_under_resampled, y_under_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d8d3e-428e-4f71-8c87-59bcbf3addb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best parameter for max_depth is: ' + str(clf_under.best_params_['max_depth']))\n",
    "print('The best parameter for n_estimators is: ' + str(clf_under.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae00ee8e-fa90-46af-b887-a58994cffc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf_under, 'Model_Saved/rf_model_Under.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75283b6-c74e-4f26-832f-7b69e8f415fb",
   "metadata": {},
   "source": [
    "### **5.1.2 Oversample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020d4ab-8af4-4608-b9de-788bb22a283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_over = RandomForestClassifier(random_state = 2, max_features = 'sqrt')\n",
    "clf_over = GridSearchCV(estimator = rf_over, param_grid = param_grid, cv = 5)\n",
    "clf_over.fit(X_over_resampled, y_over_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985c691-46c9-475b-a4b2-e91d7830ce75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The best parameter for max_depth is: ' + str(clf_over.best_params_['max_depth']))\n",
    "print('The best parameter for n_estimators is: ' + str(clf_over.best_params_['n_estimators']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289b47d4-acfb-4275-a849-7fbd19432fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(clf_over, 'Model_Saved/rf_model_Over.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a08372d-2969-42ad-8147-81bc5edc36b2",
   "metadata": {},
   "source": [
    "## **5.2 XGBooster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28291ae3-6c50-48eb-9ef8-fa116dc6e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [3, 4, 5], 'learning_rate': [0.01, 0.1, 0.2]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64996bb0-cdce-4412-8e9a-f5bf9b9a7ed9",
   "metadata": {},
   "source": [
    "### **5.2.1 Undersample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cdeee7-e2ab-491c-8377-5e9619bf4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_xgb, x_valid, y_train_xgb, y_valid = train_test_split(X_under_resampled, y_under_resampled, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd898b0-1925-4e69-96a3-85e851b8334f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_clf_under = XGBClassifier()\n",
    "grid_search_under = GridSearchCV(estimator = xgb_clf_under, param_grid = param_grid, scoring = 'accuracy', cv = 5)\n",
    "grid_search_under.fit(x_train_xgb, y_train_xgb)\n",
    "best_params_under = grid_search_under.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb86bec-46a3-48cf-8d4a-3af183e1036d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dddece-6569-495f-98f9-6f2de30f7ac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_clf_under.fit(x_train_xgb, y_train_xgb, eval_set = [(x_valid, y_valid)], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680a8d5-3238-4a28-b92a-2a9ceff7dc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_under.save_model('Model_Saved/xgb_model_under.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6690a057-1517-4365-8ce9-8f71de045f9b",
   "metadata": {},
   "source": [
    "### **5.2.2 Oversample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72c87b-81ff-4502-b9b5-3ccc8caee05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_xgb, x_valid, y_train_xgb, y_valid = train_test_split(X_over_resampled, y_over_resampled, test_size = 0.1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4120f-6514-48f8-ac2a-97233f8ba4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_over = XGBClassifier()\n",
    "grid_search_over = GridSearchCV(estimator = xgb_clf_over, param_grid = param_grid, scoring = 'accuracy', cv = 5)\n",
    "grid_search_over.fit(x_train_xgb, y_train_xgb)\n",
    "best_params_over = grid_search_under.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250d914b-9355-407f-a2d9-900c844571e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f3586-94e9-4f61-8d4f-1f6f1687a5fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_clf_over.fit(x_train_xgb, y_train_xgb, eval_set = [(x_valid, y_valid)], verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c8058-37ff-4a1c-86bb-59b8499a91da",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf_over.save_model('Model_Saved/xgb_model_over.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a88aa2-a4e2-40e6-84e1-d17fcda76626",
   "metadata": {},
   "source": [
    "## **5.3 PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19ac9c-41ed-43c2-a632-3d382c136e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(ClassifierNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        # Initialize layer1 weights using Xavier or Kaiming initialization\n",
    "        init.xavier_uniform_(self.layer1.weight)  # Xavier initialization\n",
    "        # OR\n",
    "        # init.kaiming_uniform_(self.layer1.weight, mode='fan_in', nonlinearity='relu')  # Kaiming initialization\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        # Initialize layer2 weights using Xavier or Kaiming initialization\n",
    "        init.xavier_uniform_(self.layer2.weight)  # Xavier initialization\n",
    "        # OR\n",
    "        # init.kaiming_uniform_(self.layer2.weight, mode='fan_in', nonlinearity='relu')  # Kaiming initialization\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, num_classes)\n",
    "        # Initialize output_layer weights using Xavier or Kaiming initialization\n",
    "        init.xavier_uniform_(self.output_layer.weight)  # Xavier initialization\n",
    "        # OR\n",
    "        # init.kaiming_uniform_(self.output_layer.weight, mode='fan_in', nonlinearity='relu')  # Kaiming initialization\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn1(self.layer1(x)))\n",
    "        out = self.relu(self.bn2(self.layer2(out)))\n",
    "        out = self.output_layer(out)\n",
    "        out = self.softmax(out)  # Apply softmax activation\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384d387-cd6f-4ab1-bcf2-df4b73a37fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_over_resampled.shape[1]  \n",
    "hidden_size = 20\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66a381-6987-4cca-b2b4-f623a84f254c",
   "metadata": {},
   "source": [
    "### **5.3.1 Undersample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2b99a-64ee-4a95-ab35-88549715d31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_under = ClassifierNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion_under = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer_under = optim.AdamW(model_under.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef2bcb2-c703-4555-af1a-c047e36edcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_resampled and y_resampled are numpy arrays or need to be converted from another format\n",
    "X_tensor_under = torch.tensor(X_under_resampled, dtype = torch.float32)  # Ensure dtype is correct for your model\n",
    "y_tensor_under = torch.tensor(y_under_resampled, dtype = torch.long)  # Use torch.float for regression targets\n",
    "\n",
    "dataset_under = TensorDataset(X_tensor_under, y_tensor_under)  # Wrap in TensorDataset\n",
    "train_loader_under = DataLoader(dataset_under, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e6afe-24b6-4f7e-914e-8bd24609247d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(100):  # Number of epochs\n",
    "    for inputs, labels in train_loader_under:  # Correctly iterates over batches\n",
    "        optimizer_under.zero_grad()\n",
    "        outputs = model_under(inputs)\n",
    "        loss = criterion_under(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_under.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c630d16-67e1-4d8a-b6ed-9144bd6e7b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_under, 'Model_Saved/PyTorch_Under.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a137d1-c9be-4c01-8a2b-f8e2b6c823f4",
   "metadata": {},
   "source": [
    "### **5.3.2 Oversample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edabc7ec-8468-4e70-ad1a-46b8de511175",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_over = ClassifierNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion_over = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer_over = optim.AdamW(model_over.parameters(), lr = 0.001)  # Common choice of optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c743682-6b1b-4e9c-ae23-80dcbdacc8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_resampled and y_resampled are numpy arrays or need to be converted from another format\n",
    "X_tensor_over = torch.tensor(X_over_resampled, dtype = torch.float32)  # Ensure dtype is correct for your model\n",
    "y_tensor_over = torch.tensor(y_over_resampled, dtype = torch.long)  # Use torch.float for regression targets\n",
    "\n",
    "dataset_over = TensorDataset(X_tensor_over, y_tensor_over)  # Wrap in TensorDataset\n",
    "train_loader_over = DataLoader(dataset_over, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c534f-f0f0-42c1-a194-52bf4264181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):  # Number of epochs\n",
    "    for inputs, labels in train_loader_over:  # Correctly iterates over batches\n",
    "        optimizer_over.zero_grad()\n",
    "        outputs = model_over(inputs)\n",
    "        loss = criterion_over(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_over.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4aed51-be73-4e5a-95b6-8ec4a19f8b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_over, 'Model_Saved/PyTorch_Over.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8163692-5e45-4d99-b2a3-d645ca598564",
   "metadata": {},
   "source": [
    "### **5.3.3 Original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da6c5b-224e-4e8d-bb82-c884913102d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ClassifierNN(input_size, hidden_size, num_classes)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.AdamW(model.parameters(), lr = 0.001)  # Common choice of optimizer and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954071a0-6a41-4cc2-a592-43b5cb122afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_resampled and y_resampled are numpy arrays or need to be converted from another format\n",
    "X_tensor = torch.tensor(X_train_scaled, dtype = torch.float32)  # Ensure dtype is correct for your model\n",
    "y_tensor = torch.tensor(y_train, dtype = torch.long)  # Use torch.float for regression targets\n",
    "\n",
    "dataset = TensorDataset(X_tensor, y_tensor)  # Wrap in TensorDataset\n",
    "train_loader = DataLoader(dataset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca25190-f24a-406a-aa52-d41fab01f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):  # Number of epochs\n",
    "    for inputs, labels in train_loader:  # Correctly iterates over batches\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57421a-ddbf-4cef-bbec-4ba978e005d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_over, 'Model_Saved/PyTorch.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0ccdd5-fb3c-4d8e-a7be-2a15e69e0ce8",
   "metadata": {},
   "source": [
    "# **6. Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a95112-2385-40d0-9746-69e4081fcb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_test is not binarized, binarize it\n",
    "y_test_binarized = label_binarize(y_test, classes = np.unique(y_test))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "n_classes = y_test_binarized.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8db5f7-1818-40b5-a2a2-57fc5f03c970",
   "metadata": {},
   "source": [
    "## **6.1 Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85741b02-f15b-4de5-bd9c-66cf7f3b790a",
   "metadata": {},
   "source": [
    "### **6.1.1 Undersample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31ca304-b6af-45fb-8481-65818b772119",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_under = RandomForestClassifier(n_estimators = clf_under.best_params_['n_estimators'], \n",
    "                                  max_depth = clf_under.best_params_['max_depth'], max_features = 'sqrt', \n",
    "                                  random_state = 2, n_jobs = -1)\n",
    "rf_under.fit(X_under_resampled, y_under_resampled)\n",
    "pred_y_rf_under = rf_under.predict(X_test_scaled)\n",
    "rf_under_score = rf_under .score(X_test_scaled, y_test)\n",
    "MSE_rf_under = mean_squared_error(y_test, pred_y_rf_under)\n",
    "RMSE_rf_under = np.sqrt(MSE_rf_under)\n",
    "print ('rf score: ', rf_under_score)\n",
    "print ('Mean square error of rf: ', MSE_rf_under)\n",
    "print ('Root mean squared error of rf:', RMSE_rf_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780dc19-c193-43bd-95b5-64adec831e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_y_rf_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c39bfc-d1b7-46c6-8f70-8d06b4e1eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "y_under_scores = rf_under.predict_proba(X_test_scaled)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_under_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting ROC curves\n",
    "plt.figure(figsize = (7, 5))\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color = color, lw = 2,\n",
    "             label = 'ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('RandomForest Undersampled Multi-class ROC')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376f017-221d-44ad-8bce-1549449d0452",
   "metadata": {},
   "source": [
    "### **6.1.2 Oversample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e6712-55c5-49d1-a993-3fae3c476743",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_over = RandomForestClassifier(n_estimators = clf_over.best_params_['n_estimators'], \n",
    "                                 max_depth = clf_over.best_params_['max_depth'],\n",
    "                                 max_features = 'sqrt', random_state = 2, n_jobs = -1)\n",
    "rf_over.fit(X_over_resampled, y_over_resampled)\n",
    "pred_y_rf_over = rf_over.predict(X_test_scaled)\n",
    "rf_over_score = rf_over.score(X_test_scaled, y_test)\n",
    "MSE_rf_over = mean_squared_error(y_test, pred_y_rf_over)\n",
    "RMSE_rf_over = np.sqrt(MSE_rf_over)\n",
    "print ('rf score: ', rf_over_score)\n",
    "print ('Mean square error of rf: ', MSE_rf_over)\n",
    "print ('Root mean squared error of rf:', RMSE_rf_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069867c-915a-45df-b6eb-26571fc13dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred_y_rf_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ecff5-b072-45d9-997b-a67d6622aceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "y_over_scores = rf_over.predict_proba(X_test_scaled)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_over_scores[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plotting ROC curves\n",
    "plt.figure(figsize = (7, 5))\n",
    "colors = ['aqua', 'darkorange', 'cornflowerblue', 'green', 'red', 'purple', 'brown', 'pink', 'gray', 'olive']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color = color, lw = 2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('RandomForest Oversampled Multi-class ROC')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c900fd59-b1c8-4271-a535-e14133bf7a7c",
   "metadata": {},
   "source": [
    "## **6.2 XGBooster**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d2927-1066-4767-abac-d541f65301ee",
   "metadata": {},
   "source": [
    "### **6.2.1 Undersample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc0ae7-9b2c-47b1-aee0-1d18673e0d7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y_xgb_under = xgb_clf_under.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, pred_y_xgb_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5f7bd-b4d7-496e-8a83-c0eac4e11f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_score_under = xgb_clf_under.score(X_test_scaled, y_test)\n",
    "MSE_xgb_under = mean_squared_error(y_test, pred_y_xgb_under)\n",
    "RMSE_xgb_under = np.sqrt(MSE_xgb_under)\n",
    "print ('xgb score: ', xgb_score_under)\n",
    "print ('Mean square error of xgb: ', MSE_xgb_under)\n",
    "print ('Root mean squared error of xgb:', RMSE_xgb_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5edfda-0501-42c6-bfd3-09af5b7ebfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "y_prob_under = xgb_clf_under.predict_proba(X_test_scaled)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob_under[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, n_classes)))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=next(colors), lw = 2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw = 2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('XGBooster Undersampled Multi-class ROC')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4535295-84d2-4346-bf8f-24e560b5c4c4",
   "metadata": {},
   "source": [
    "### **6.2.2 Oversample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c5ffe-da1e-4eb9-abbe-273c72775fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_xgb_over = xgb_clf_over.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, pred_y_xgb_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522db51-1e3a-46e9-82ca-65af6848da7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_score_over = xgb_clf_over.score(X_test_scaled, y_test)\n",
    "MSE_xgb_over = mean_squared_error(y_test, pred_y_xgb_over)\n",
    "RMSE_xgb_over = np.sqrt(MSE_xgb_over)\n",
    "print ('xgb score: ', xgb_score_over)\n",
    "print ('Mean square error of xgb: ', MSE_xgb_over)\n",
    "print ('Root mean squared error of xgb:', RMSE_xgb_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8a732-5ec6-4de0-9455-a1c636d7b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "y_prob_over = xgb_clf_over.predict_proba(X_test_scaled)\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob_over[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "plt.figure(figsize = (7, 5))\n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, n_classes)))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color=next(colors), lw = 2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw = 2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('XGBooster Oversampled Multi-class ROC')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e50de3-2e89-466d-9216-15fcdb3b5dc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **6.3 PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9dca2-2338-468f-be9c-ae00bba18882",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test_scaled, dtype = torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype = torch.long)  # Ensure y_test is in the correct format\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = True)  # Adjust batch_size as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f686f-d611-4231-b1f5-c9519e7617a0",
   "metadata": {},
   "source": [
    "### **6.3.1 Undersample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7d935-dcd8-4c4a-a007-d4cc73aac9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_under.eval()  # Set the model to evaluation mode\n",
    "predictions_under = []\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, _ in test_loader:\n",
    "        outputs = model_under(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions_under.extend(predicted.numpy())  # Store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad041d-7f77-4300-bf4e-ba800a168bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_score_under = accuracy_score(y_test, predictions_under)\n",
    "MSE_pytorch_under = mean_squared_error(y_test, predictions_under)\n",
    "RMSE_pytorch_under = np.sqrt(MSE_pytorch_under)\n",
    "print ('PyTorch score: ', pytorch_score_under)\n",
    "print ('Mean square error of PyTorch: ', MSE_pytorch_under)\n",
    "print ('Root mean squared error of PyTorch:', RMSE_pytorch_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5916d7-d4b0-4a0f-9039-536b1c72323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_pytorch_under = []\n",
    "\n",
    "with torch.no_grad():  # Inference without gradient calculation\n",
    "    for inputs in DataLoader(X_test_tensor, batch_size = 64):\n",
    "        outputs = model_under(inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim = 1)\n",
    "        y_prob_pytorch_under.extend(probabilities.numpy())\n",
    "\n",
    "y_prob_pytorch_under = np.array(y_prob_pytorch_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15432155-9daa-4712-8119-5f963633ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2103e-5b8d-4872-b2dc-cfb3df40dbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob_pytorch_under[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Step 4: Plotting\n",
    "plt.figure(figsize = (7, 5))\n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, n_classes)))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color = next(colors), lw = 2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw = 2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('PyTorch Undersampled Multi-class ROC')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e42f566-c045-4994-8ea6-fa18b9a915e0",
   "metadata": {},
   "source": [
    "### **6.3.2 Oversample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68af519-1a55-4475-8608-a5c0496eecc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_over.eval()  # Set the model to evaluation mode\n",
    "predictions_over = []\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, _ in test_loader:\n",
    "        outputs = model_over(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions_over.extend(predicted.numpy())  # Store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d6626-2b50-4e17-8b69-d1b9826fd480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_score_over = accuracy_score(y_test, predictions_over)\n",
    "MSE_pytorch_over = mean_squared_error(y_test, predictions_over)\n",
    "RMSE_pytorch_over = np.sqrt(MSE_pytorch_over)\n",
    "print ('PyTorch score: ', pytorch_score_over)\n",
    "print ('Mean square error of PyTorch: ', MSE_pytorch_over)\n",
    "print ('Root mean squared error of PyTorch:', RMSE_pytorch_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa6c3a-6350-4f69-8bfb-ac73b6e7c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions_over))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8359659-4bdd-4b60-866f-f05df769d428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_over.eval()  # Set the model to evaluation mode\n",
    "y_prob_pytorch_over = []\n",
    "\n",
    "with torch.no_grad():  # Inference without gradient calculation\n",
    "    for inputs in DataLoader(X_test_tensor, batch_size = 64):\n",
    "        outputs = model_over(inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim = 1)\n",
    "        y_prob_pytorch_over.extend(probabilities.numpy())\n",
    "\n",
    "y_prob_pytorch_over = np.array(y_prob_pytorch_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514eb99-8d14-4575-8051-805eaf5c17cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob_pytorch_over[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Step 4: Plotting\n",
    "plt.figure(figsize = (7, 5))\n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, n_classes)))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color = next(colors), lw = 2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw = 2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('PyTorch Oversampled Multi-class ROC')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d3b8f-8783-4163-aa1c-1f1aefa84ff3",
   "metadata": {},
   "source": [
    "### **6.3.3 Original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abe9d24-35ba-4c2d-9479-fbf757d2cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "with torch.no_grad():  # Do not compute gradients\n",
    "    for inputs, _ in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.numpy())  # Store predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611f5e5-8751-47ab-9cde-daf4012376db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_score = accuracy_score(y_test, predictions)\n",
    "MSE_pytorch = mean_squared_error(y_test, predictions)\n",
    "RMSE_pytorch = np.sqrt(MSE_pytorch)\n",
    "print ('PyTorch score: ', pytorch_score)\n",
    "print ('Mean square error of PyTorch: ', MSE_pytorch)\n",
    "print ('Root mean squared error of PyTorch:', RMSE_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546fc58-5249-4f49-ac04-c5f24e318995",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_pytorch = []\n",
    "\n",
    "with torch.no_grad():  # Inference without gradient calculation\n",
    "    for inputs in DataLoader(X_test_tensor, batch_size = 64):\n",
    "        outputs = model(inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim = 1)\n",
    "        y_prob_pytorch.extend(probabilities.numpy())\n",
    "\n",
    "y_prob_pytorch = np.array(y_prob_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ee218-a4a3-4941-9bb6-9304ca1ce38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_prob_pytorch[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Step 4: Plotting\n",
    "plt.figure(figsize = (5, 4))\n",
    "colors = iter(plt.cm.rainbow(np.linspace(0, 1, n_classes)))\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], color = next(colors), lw = 2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw = 2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-class ROC for PyTorch Model')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cb16fe-dabd-453b-ab5b-6e6ee971c56a",
   "metadata": {},
   "source": [
    "# **7. Feature Importance**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbcb0cb-e66d-4a30-a9e2-9ae68ba8d19b",
   "metadata": {},
   "source": [
    "## **7.1 Undersample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702b61ea-13d0-405b-bf28-b14d25cd8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_under.feature_importances_\n",
    "feature_name = X_train.columns.values\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(1)\n",
    "plt.bar(feature_name[indices[:20]], importances[indices[:20]])\n",
    "plt.title('First 20 Important Features In Undersampled')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4d0fc-413f-4446-8dd9-5d780d13d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf_over.feature_importances_\n",
    "feature_name = X_train.columns.values\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(1)\n",
    "plt.bar(feature_name[indices[:20]], importances[indices[:20]])\n",
    "plt.title('First 20 Important Features In Oversampled')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74116059-07c9-4972-ae36-04b9755ee293",
   "metadata": {},
   "source": [
    "# **8. Deeper Analysis About The Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41052d76-eed7-4f3a-8f59-18cfc7c3528b",
   "metadata": {},
   "source": [
    "## **8.1 The First Seven Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec46c25-8d38-4ea3-8dc5-d97acf2dbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_7 = [n for n in range(0, 7)]\n",
    "first_7_df = spotify_df[spotify_df['genre'].isin(first_7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e746b0dc-2897-4b61-9109-5a78389de4cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_7 = first_7_df.corr()\n",
    "corr_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87c895-90bf-4bb2-be1a-43d60fb2d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_7, cmap = \"YlGnBu\")\n",
    "plt.title('Correlation For The First Seven Classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6d0172-68d3-4862-a04e-9e0d91904899",
   "metadata": {},
   "source": [
    "## **8.2 The Last Three Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0477a-9728-42ee-8f05-0adb6cab1a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last_3 = [7, 8, 9]\n",
    "last_3_df = spotify_df[spotify_df['genre'].isin(last_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c1f17-59e0-4499-9fc7-d38e7afa6ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr_3 = last_3_df.corr()\n",
    "corr_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a771dc4-c9b1-4db6-a700-d1f952eb3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corr_3, cmap = \"YlGnBu\")\n",
    "plt.title('Correlation For The Last Three Classes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a206182-dcd8-482d-8846-1e831f6be86a",
   "metadata": {},
   "source": [
    "# **9. Revenue Forecast**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b88d92-f102-4167-ac05-75c462c13754",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predict'] = pred_y_xgb_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4f9755-a7bb-49c1-9431-b1eb7e3c80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test, y_test], axis = 1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947a2db-fb02-4bf0-94a0-71a6cc7791dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_streams_history = test_df.groupby(by = 'genre')['streams'].mean()\n",
    "avg_streams_history = pd.DataFrame(avg_streams_history)\n",
    "avg_streams_history.columns = ['Historical']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d4b1a-d66a-4fd5-8cc4-a10a3419734b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_streams_predict = test_df.groupby(by = 'predict')['streams'].mean()\n",
    "avg_streams_predict = pd.DataFrame(avg_streams_predict)\n",
    "avg_streams_predict.columns = ['Predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe74781f-5303-47a4-bee8-f1a2e671147c",
   "metadata": {},
   "source": [
    "## **9.1 Streams Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dab31e-5b78-49e4-9672-d8f08e95e9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_list = [genre_mapping[key] for key in sorted(genre_mapping.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b343e9a1-7191-41bb-96c1-909c550a0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_compare = pd.concat([avg_streams_history, avg_streams_predict], axis = 1)\n",
    "streams_compare.index = genre_list\n",
    "streams_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a86e6-d614-4c1e-b2eb-c5a8dd197ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_compare.hvplot.bar(y=['Historical', 'Predicted'], stacked = False, xlabel = 'Genre', ylabel = 'Streams',\n",
    "                           title = 'Historical vs Predicted Streams Comparison', rot = 45, \n",
    "                           width = 800, height = 500).opts(yformatter = '%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb9873b-945a-41e1-b110-33d7376731cf",
   "metadata": {},
   "source": [
    "## **9.2 Revenue Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b717f-4787-4a20-b071-bf0729f05834",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_per_stream = 0.004  # As an example, using the mid-point of the range\n",
    "revenue_compare = pd.DataFrame(index = top10_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f5d52-128d-464e-b7cb-abf528ae3a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_compare['Historical'] = streams_compare['Historical'] * revenue_per_stream\n",
    "revenue_compare['Predicted'] = streams_compare['Predicted'] * revenue_per_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4cba2d-6478-403e-92a4-e1fee5c91a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_compare.hvplot.bar(y=['Historical', 'Predicted'], stacked = False, xlabel = 'Genre', ylabel = 'Revenue',\n",
    "                           title = 'Historical vs Predicted Revenue Comparison', rot = 45, \n",
    "                           width = 800, height = 500).opts(yformatter = '%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2296fe1-35cb-4d37-a81a-d54125cb9243",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
